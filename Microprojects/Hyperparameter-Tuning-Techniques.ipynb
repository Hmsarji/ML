{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 accuracy: 0.9590643274853801\n",
      "Model 2 accuracy: 0.9590643274853801\n",
      "Model 3 accuracy: 0.9707602339181286\n",
      "Duration for Grid Search Example: 0:02:37.439434\n",
      "Best model training score for Grid Search Example: 0.954778481012658\n",
      "Best hyperparameters for Grid Search Example: {'bootstrap': True, 'criterion': 'gini', 'max_features': 10, 'min_samples_leaf': 5, 'min_samples_split': 11, 'n_estimators': 30}\n",
      "Best model accuracy for Grid Search Example: 0.9707602339181286\n",
      "Duration for Halving Grid Search: 0:01:08.292767\n",
      " Best model training score for Halving Grid Search: 1.0\n",
      "Best hyperparameters for Halving Grid Search: {'bootstrap': False, 'criterion': 'entropy', 'max_features': 10, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best model accuracy for Halving Grid Search: 0.9707602339181286\n",
      "Duration for Random Search Example: 0:00:07.923801\n",
      "Best model training score for Random Search Example: 0.9497784810126582\n",
      "Best hyperparameters for Random Search Example: {'bootstrap': True, 'criterion': 'entropy', 'max_features': 24, 'min_samples_leaf': 3, 'min_samples_split': 9, 'n_estimators': 59}\n",
      "Best model accuracy for Random Search Example: 0.9649122807017544\n",
      "Duration for Halving Random Search: 0:00:05.435967\n",
      "Best model training score for Halving Random Search: 1.0\n",
      "Best hyperparameters for Halving Random Search: {'bootstrap': True, 'criterion': 'gini', 'max_features': 24, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 50}\n",
      "Best model accuracy for Halving Random Search: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets # Import the datasets module from scikit-learn to load sample datasets\n",
    "import pandas as pd # Import pandas for data manipulation and analysis (e.g., creating DataFrames)\n",
    "from scipy.stats import randint as sp_rand # Import randint from scipy.stats for generating random integers (used in hyperparameter tuning)\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split to split the dataset into training and testing sets\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier for building a random forest classification model\n",
    "from sklearn.metrics import accuracy_score # Import accuracy_score to evaluate the accuracy of the model\n",
    "from sklearn.experimental import enable_halving_search_cv # Enable experimental halving search CV (cross-validation) methods for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV # Import GridSearchCV and HalvingGridSearchCV for hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, HalvingRandomSearchCV # Import RandomizedSearchCV and HalvingRandomSearchCV for hyperparameter tuning\n",
    "from datetime import datetime # Import datetime to record the current date and time\n",
    "\n",
    "\n",
    "# Load the Breast cancer dataset from scikit-learn library and convert it to a pandas DataFrame\n",
    "dataset = datasets.load_breast_cancer() # Load the Breast cancer dataset\n",
    "data = pd.DataFrame(dataset.data, columns=dataset.feature_names)    # Convert the dataset to a pandas DataFrame\n",
    "data['target'] = dataset.target # Add the target column to the DataFrame\n",
    "data.head() # Display the first few rows of the DataFrame\n",
    "\n",
    "# Creating dataset variables\n",
    "X = dataset.data # Features\n",
    "Y = dataset.target  # Target\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42) # Split the dataset into training and testing sets\n",
    "\n",
    "\n",
    "# Manual Search\n",
    "# ----------------------------Hyperparameter Space--------------------------------\n",
    "params_1 = {'n_estimators': 10, # Number of trees in the forest \n",
    "            'criterion': 'entropy', # The function to measure the quality of a split\n",
    "            'max_features': 15, # The number of features to consider when looking for the best split\n",
    "            'min_samples_split': 6, # The minimum number of samples required to split an internal node\n",
    "            'min_samples_leaf': 8, # The minimum number of samples required to be at a leaf node\n",
    "            'bootstrap': True} # Whether bootstrap samples are used when building trees\n",
    "\n",
    "params_2 = {'n_estimators': 50, # Number of trees in the forest \n",
    "            'criterion': 'entropy', # The function to measure the quality of a split\n",
    "            'max_features': 30, # The number of features to consider when looking for the best split\n",
    "            'min_samples_split': 10, # The minimum number of samples required to split an internal node\n",
    "            'min_samples_leaf': 11, # The minimum number of samples required to be at a leaf node\n",
    "            'bootstrap': True} # Whether bootstrap samples are used when building trees\n",
    "\n",
    "params_3 = {'n_estimators': 80, # Number of trees in the forest \n",
    "            'criterion': 'gini', # The function to measure the quality of a split\n",
    "            'max_features': 30, # The number of features to consider when looking for the best split\n",
    "            'min_samples_split': 10, # The minimum number of samples required to split an internal node\n",
    "            'min_samples_leaf': 6, # The minimum number of samples required to be at a leaf node\n",
    "            'bootstrap': False} # Whether bootstrap samples are used when building trees\n",
    "\n",
    "# ----------------------------Create and fit the model--------------------------------\n",
    "model_1 = RandomForestClassifier(**params_1)\n",
    "model_2 = RandomForestClassifier(**params_2)\n",
    "model_3 = RandomForestClassifier(**params_3)\n",
    "\n",
    "#Training Models\n",
    "model_1.fit(X_train, Y_train)\n",
    "model_2.fit(X_train, Y_train)\n",
    "model_3.fit(X_train, Y_train)\n",
    "\n",
    "# Results \n",
    "print(f'Model 1 accuracy: {model_1.score(X_test, Y_test)}')\n",
    "print(f'Model 2 accuracy: {model_2.score(X_test, Y_test)}')\n",
    "print(f'Model 3 accuracy: {model_3.score(X_test, Y_test)}')\n",
    "\n",
    "\n",
    "\n",
    "# Grid Search Example\n",
    "#-----------------------------Hyperparameter Space--------------------------------\n",
    "h_space = {'n_estimators': [30, 60, 80, 100],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_features': [10, 20, 25, 30],\n",
    "              'min_samples_split': [5, 11],\n",
    "              'min_samples_leaf': [5, 11],\n",
    "              'bootstrap': [True, False]}\n",
    "# Creating and fitting the model\n",
    "Random_forest_clf = RandomForestClassifier()\n",
    "\n",
    "#Creating and training the models\n",
    "#The datetime function has been used to calculate operation time\n",
    "start = datetime.now()\n",
    "models = GridSearchCV(Random_forest_clf, param_grid=h_space, cv=5)\n",
    "models.fit(X_train, Y_train)\n",
    "end = datetime.now()\n",
    "\n",
    "# Getting 5-fold cross-validation results\n",
    "scores = models.cv_results_['mean_test_score']\n",
    "# Getting best hyperparameters\n",
    "best_hparams = models.best_params_\n",
    "\n",
    "print(f'Duration for Grid Search Example: {end-start}')\n",
    "print(f'Best model training score for Grid Search Example: {max(scores)}')\n",
    "print(f'Best hyperparameters for Grid Search Example: {best_hparams}')\n",
    "\n",
    "\n",
    "#-----------------------------Training the model--------------------------------\n",
    "# Training the model with the best hyperparameters from the Grid Search\n",
    "best_model = RandomForestClassifier(bootstrap= True,\n",
    "                                    criterion = 'entropy',\n",
    "                                    max_features = 10,\n",
    "                                    min_samples_leaf = 5,\n",
    "                                    min_samples_split= 5,\n",
    "                                    n_estimators= 80)\n",
    "best_model.fit(X_train, Y_train)\n",
    "print(f'Best model accuracy for Grid Search Example: {best_model.score(X_test, Y_test)}')\n",
    "\n",
    "\n",
    "\n",
    "#Halving Grid Search Example\n",
    "#-----------------------------Hyperparameter Space--------------------------------\n",
    "h_space = {'n_estimators': [30, 60, 80, 100],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_features': [10, 20, 25, 30],\n",
    "              'min_samples_split': [5, 11],\n",
    "              'min_samples_leaf': [5, 11],\n",
    "              'bootstrap': [True, False]}\n",
    "# Creating and fitting the model\n",
    "Random_forest_clf = RandomForestClassifier()\n",
    "# -----------------------------Create and fit the model-------------------------------\n",
    "# The hyperparameter space is the same as the grid search\n",
    "start = datetime.now()\n",
    "# The datetime function has been used to calculate operation time \n",
    "models = HalvingGridSearchCV(Random_forest_clf,\n",
    "                             param_grid = h_space, cv = 5)\n",
    "models.fit(X_train, Y_train)\n",
    "end = datetime.now()\n",
    "\n",
    "#Getting 5-fold cross validated score\n",
    "scores = models.cv_results_['mean_test_score']\n",
    "# Getting best hyperparameters\n",
    "best_hparams = models.best_params_\n",
    "\n",
    "print(f'Duration for Halving Grid Search: {end-start}')\n",
    "print(f' Best model training score for Halving Grid Search: {max(scores)}')\n",
    "print(f'Best hyperparameters for Halving Grid Search: {best_hparams}') \n",
    "\n",
    "#-----------------------------Training the model--------------------------------\n",
    "# Training the model with the best hyperparameters from the Halving Grid Search\n",
    "best_model = RandomForestClassifier(bootstrap= True,\n",
    "                                    criterion = 'gini',\n",
    "                                    max_features = 10,\n",
    "                                    min_samples_leaf = 5,\n",
    "                                    min_samples_split= 5,\n",
    "                                    n_estimators= 100)\n",
    "best_model.fit(X_train, Y_train)    \n",
    "print(f'Best model accuracy for Halving Grid Search: {best_model.score(X_test, Y_test)}')\n",
    "\n",
    "# --------------------------------Random Search Example--------------------------------\n",
    "# ----------------------------Hyperparameter Space--------------------------------\n",
    "h_space = {'bootstrap': [True, False],\n",
    "           'criterion': ['gini', 'entropy'],\n",
    "           'max_features': sp_rand(20,30),\n",
    "           'min_samples_split': sp_rand(2,11),\n",
    "           'min_samples_leaf': sp_rand(2,11),\n",
    "           'n_estimators': sp_rand(30, 100)}\n",
    "\n",
    "# ----------------------------Create and fit the model--------------------------------\n",
    "start = datetime.now()\n",
    "models = RandomizedSearchCV(Random_forest_clf, param_distributions=h_space, cv = 5, random_state=42)\n",
    "models.fit(X_train, Y_train)\n",
    "end = datetime.now()\n",
    "\n",
    "# Getting 5-fold cross-validation results\n",
    "scores = models.cv_results_['mean_test_score']\n",
    "# Getting best hyperparameters\n",
    "best_hparams = models.best_params_\n",
    "\n",
    "print(f'Duration for Random Search Example: {end-start}')\n",
    "print(f'Best model training score for Random Search Example: {max(scores)}')\n",
    "print(f'Best hyperparameters for Random Search Example: {best_hparams}')\n",
    "\n",
    "# ----------------------------Training the model--------------------------------\n",
    "# Training the model with the best hyperparameters from the Random Search\n",
    "best_model = RandomForestClassifier(bootstrap= True,\n",
    "                                    criterion = 'gini',\n",
    "                                    max_features = 24,\n",
    "                                    min_samples_leaf = 4,\n",
    "                                    min_samples_split= 8,\n",
    "                                    n_estimators= 50)\n",
    "\n",
    "best_model.fit(X_train, Y_train)\n",
    "print(f'Best model accuracy for Random Search Example: {best_model.score(X_test, Y_test)}')\n",
    "\n",
    "\n",
    "# ----------------------------Halving Random Search Example--------------------------------\n",
    "# ----------------------------Hyperparameter Space--------------------------------\n",
    "h_space = {'bootstrap': [True, False],\n",
    "           'criterion': ['gini', 'entropy'],\n",
    "           'max_features': sp_rand(20,30),\n",
    "           'min_samples_split': sp_rand(2,11),\n",
    "           'min_samples_leaf': sp_rand(2,11),\n",
    "           'n_estimators': sp_rand(30, 100)}\n",
    "start = datetime.now()\n",
    "models = HalvingRandomSearchCV(Random_forest_clf, param_distributions=h_space, cv = 5, random_state=42)\n",
    "models.fit(X_train, Y_train)\n",
    "end = datetime.now()\n",
    "#Getting 5-fold cross validated score\n",
    "scores = models.cv_results_['mean_test_score'] \n",
    "# Getting best hyperparameters\n",
    "best_hparams = models.best_params_\n",
    "\n",
    "print(f'Duration for Halving Random Search: {end-start}')\n",
    "print(f'Best model training score for Halving Random Search: {max(scores)}')\n",
    "print(f'Best hyperparameters for Halving Random Search: {best_hparams}')\n",
    "\n",
    "# ----------------------------Training the model--------------------------------\n",
    "# Training the model with the best hyperparameters from the Halving Random Search\n",
    "best_model = RandomForestClassifier(bootstrap= True,\n",
    "                                    criterion = 'entropy',\n",
    "                                    max_features = 24,\n",
    "                                    min_samples_leaf = 3,\n",
    "                                    min_samples_split= 9,\n",
    "                                    n_estimators= 59)\n",
    "best_model.fit(X_train, Y_train)\n",
    "print(f'Best model accuracy for Halving Random Search: {best_model.score(X_test, Y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
