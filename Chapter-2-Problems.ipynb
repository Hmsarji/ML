{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.812\n",
      "RMSE: 1.6769019053003666\n",
      "MAE: 1.6\n",
      "MAPE 61.16666666666667\n"
     ]
    }
   ],
   "source": [
    "# Problem 6\n",
    "\n",
    "A = [1, 2, 3, 4, 5]\n",
    "B = [0, 0.9, 1.4, 1.7, 7]\n",
    "\n",
    "#Defining MSE Function\n",
    "def MSE(A, B):\n",
    "    return sum((a - b) ** 2 for a, b in zip(A, B)) / len(A)\n",
    "print(f'MSE: {MSE(A, B)}')\n",
    "\n",
    "\n",
    "#Defining RMSE Function \n",
    "def RMSE(A,B):\n",
    "    return (sum((a-b)**2 for a,b in zip(A,B))/len(A))**0.5\n",
    "print(f'RMSE: {RMSE(A,B)}')\n",
    "\n",
    "#Defining MAE Function\n",
    "def MAE(A,B):\n",
    "    return sum(abs(a-b) for a,b in zip(A,B))/len(A)\n",
    "print(f'MAE: {MAE(A,B)}') \n",
    "\n",
    "#Defining MAPE Function \n",
    "\n",
    "def MAPE(A,B):\n",
    "    return sum(abs((a-b)/a) for a,b in zip(A,B))/len(A) *100 \n",
    "print(f'MAPE {MAPE(A,B)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huber Loss: 58.961\n",
      "MSE: 745.1220000000001\n"
     ]
    }
   ],
   "source": [
    "#Problem 7 \n",
    "\n",
    "A = [80, 86, 89, 95, 98] \n",
    "B = [81, 84.5, 150, 95.6, 99]\n",
    "#Defining the huber loss\n",
    "def huber_Loss(y_true, y_pred, delta):\n",
    "    Loss = 0\n",
    "    for y_t, y_p in zip(y_true, y_pred):\n",
    "        error = y_t - y_p\n",
    "        if abs(error) <= delta:\n",
    "            Loss += 0.5 * error ** 2\n",
    "        else:\n",
    "            Loss += delta * (abs(error) - 0.5 * delta)\n",
    "    return Loss / len(y_true)\n",
    "print(f'Huber Loss: {huber_Loss(A,B,5)}')\n",
    "            \n",
    "#Defining MSE Function\n",
    "def MSE(A, B):\n",
    "    return sum((a - b) ** 2 for a, b in zip(A, B)) / len(A)\n",
    "print(f'MSE: {MSE(A, B)}')       \n",
    "\n",
    "\n",
    "# MSE Method is more effected by the outlier (150) than the huber loss method. \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.020202707317519466\n",
      "Cross Entropy: 0.020202707317519466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.020202707317519466"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "\n",
    "    # Ensure inputs are numpy arrays\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    \n",
    "    # Clip predictions to avoid log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Calculate cross entropy\n",
    "    cross_entropy_value = -np.sum(y_true * np.log(y_pred))\n",
    "    print(f'Cross Entropy: {cross_entropy_value}')\n",
    "    return cross_entropy_value\n",
    "\n",
    "# Test cases\n",
    "y_pred_1 = 0.98\n",
    "y_true_1 = 1\n",
    "cross_entropy(y_true_1, y_pred_1)  \n",
    "\n",
    "y_pred_2 = [0.2, 0.98]\n",
    "y_true_2 = [0, 1]\n",
    "cross_entropy(y_true_2, y_pred_2)  \n",
    "\n",
    "# The binary cross entropy loss and categorical cross entropy loss are equivalent in this case because the multiclass problem is essentially a binary problem with two c lasses\n",
    "# The loss value 0.0202 indicates that the model is performing well. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance: 100.65286881157436\n",
      "Manhattan Distance: 169\n",
      "Chebyshev Distance: 82\n",
      "Cosine Distance: 0.630305615128243\n",
      "Minkowski Distance: 88.50114376042109\n"
     ]
    }
   ],
   "source": [
    "#Problem 11\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "A =np.array([7, 30, 0, 9, 87])\n",
    "B =np.array([4, 67, 2, 54, 5])\n",
    "\n",
    "def Euclidean_distance(A, B):\n",
    "    Euclidean_distance = np.sqrt(np.sum((A-B)**2))\n",
    "    print(f'Euclidean Distance: {Euclidean_distance}')\n",
    "    return\n",
    "Euclidean_distance(A,B)\n",
    "\n",
    "def Manhattan_distance(A,B):\n",
    "    Manhattan_distance = np.sum(np.abs(A-B))\n",
    "    print(f'Manhattan Distance: {Manhattan_distance}')\n",
    "    return\n",
    "Manhattan_distance(A,B)\n",
    "\n",
    "def Chebyshev_distance(A,B):\n",
    "    Chebyshev_distance = np.max(np.abs(A-B))\n",
    "    print(f'Chebyshev Distance: {Chebyshev_distance}')\n",
    "    return\n",
    "Chebyshev_distance(A,B)\n",
    "\n",
    "def Cosine_distance(A,B):\n",
    "    Cosine_distance = 1 - (np.dot(A,B) / (np.linalg.norm(A) * np.linalg.norm(B)))\n",
    "    print(f'Cosine Distance: {Cosine_distance}')\n",
    "    return\n",
    "Cosine_distance(A,B)\n",
    "\n",
    "def Minkowski_distance(A,B,p):\n",
    "    Minkowski_distance = np.sum(np.abs(A-B)**p)**(1/p)\n",
    "    print(f'Minkowski Distance: {Minkowski_distance}')\n",
    "    return\n",
    "Minkowski_distance(A,B,3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Distance: 4\n"
     ]
    }
   ],
   "source": [
    "#Problem 12\n",
    "# Hamming distance function \n",
    "def hamming_distance(S1, S2):\n",
    "    dist = 0 \n",
    "    if len(S1) != len(S2):\n",
    "        print('Strings must be of equal length')\n",
    "    else:\n",
    "        for x, (i,j) in enumerate(zip(S1,S2)):\n",
    "            if i != j:\n",
    "                dist += 1\n",
    "    print(f'Hamming Distance: {dist}')\n",
    "    return \n",
    "\n",
    "Sample_A = 'AATGCATTCG'\n",
    "Sample_B = 'AATCGATTGC'\n",
    "hamming_distance(Sample_A, Sample_B) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word set Sentence 1: {'beach', 'soccer', 'playing', 'men'}\n",
      "Word set Sentence 2: {'playing', 'soccer', 'boys', 'near', 'beach'}\n",
      "Intersection: {'beach', 'playing', 'soccer'}\n",
      "Union: {'playing', 'soccer', 'boys', 'near', 'beach', 'men'}\n",
      "Jaccard Similarity: 0.5\n",
      "Unified Vocabulary: ['beach', 'boys', 'men', 'near', 'playing', 'soccer']\n",
      "S1 Vector: [1, 0, 1, 0, 1, 1]\n",
      "S2 Vector: [1, 1, 0, 1, 1, 1]\n",
      "Cosine Similarity: 0.6708203932499369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Husse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Husse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to calculate Jaccard Similarity\n",
    "def jaccard_similarity(S1, S2):\n",
    "    # Tokenize sentences and remove stopwords\n",
    "    S1_list = word_tokenize(S1.lower())  # Convert to lowercase for consistency\n",
    "    S2_list = word_tokenize(S2.lower())\n",
    "    sw = set(stopwords.words('english'))  # Use a set for faster lookup\n",
    "    S1_set = {w for w in S1_list if w.isalnum() and w not in sw}  # Keep only alphanumeric words\n",
    "    S2_set = {w for w in S2_list if w.isalnum() and w not in sw}\n",
    "\n",
    "    print(f'Word set Sentence 1: {S1_set}')\n",
    "    print(f'Word set Sentence 2: {S2_set}')\n",
    "\n",
    "    # Calculate intersection and union\n",
    "    I = S1_set.intersection(S2_set)\n",
    "    U = S1_set.union(S2_set)\n",
    "\n",
    "    print(f'Intersection: {I}')\n",
    "    print(f'Union: {U}')\n",
    "\n",
    "    # Jaccard Similarity\n",
    "    IoU = len(I) / len(U)\n",
    "    print(f'Jaccard Similarity: {IoU}')\n",
    "    return IoU\n",
    "\n",
    "# Function to calculate Cosine Similarity\n",
    "def cosine_similarity(S1, S2):\n",
    "    # Tokenize sentences and remove stopwords\n",
    "    S1_list = word_tokenize(S1.lower())  # Convert to lowercase for consistency\n",
    "    S2_list = word_tokenize(S2.lower())\n",
    "    sw = set(stopwords.words('english'))  # Use a set for faster lookup\n",
    "    S1_set = {w for w in S1_list if w.isalnum() and w not in sw}  # Keep only alphanumeric words\n",
    "    S2_set = {w for w in S2_list if w.isalnum() and w not in sw}\n",
    "\n",
    "    # Create a unified vocabulary (sorted for consistency)\n",
    "    U = sorted(S1_set.union(S2_set))\n",
    "\n",
    "    # Create word frequency vectors\n",
    "    S1_vector = [1 if word in S1_set else 0 for word in U]\n",
    "    S2_vector = [1 if word in S2_set else 0 for word in U]\n",
    "\n",
    "    print(f'Unified Vocabulary: {U}')\n",
    "    print(f'S1 Vector: {S1_vector}')\n",
    "    print(f'S2 Vector: {S2_vector}')\n",
    "\n",
    "    # Cosine Similarity\n",
    "    dot_product = np.dot(S1_vector, S2_vector)\n",
    "    norm_S1 = np.linalg.norm(S1_vector)\n",
    "    norm_S2 = np.linalg.norm(S2_vector)\n",
    "    cosine_sim = dot_product / (norm_S1 * norm_S2)\n",
    "    print(f'Cosine Similarity: {cosine_sim}')\n",
    "    return cosine_sim\n",
    "\n",
    "# Sentences\n",
    "S1 = 'The men are playing soccer on the beach'\n",
    "S2 = 'The boys are playing soccer near the beach'\n",
    "\n",
    "# Calculate Jaccard Similarity\n",
    "jaccard_sim = jaccard_similarity(S1, S2)\n",
    "\n",
    "# Calculate Cosine Similarity\n",
    "cosine_sim = cosine_similarity(S1, S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9538461538461539\n",
      "Precision: 0.927536231884058\n",
      "Recall: 0.9846153846153847\n",
      "F1 Score: 0.9552238805970149\n",
      "Accuracy: 0.9538461538461539\n",
      "Precision: 0.9836065573770492\n",
      "Recall: 0.9230769230769231\n",
      "F1 Score: 0.9523809523809524\n"
     ]
    }
   ],
   "source": [
    "true_positive = 128 \n",
    "false_positive = 120 - 110\n",
    "true_negative = 120\n",
    "false_negative = 130 -128\n",
    "accuracy = (true_positive + true_negative) / (true_positive + false_positive + true_negative + false_negative) \n",
    "print(f'Accuracy: {accuracy}')\n",
    "precision = true_positive / (true_positive + false_positive) \n",
    "print(f'Precision: {precision}')   \n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "print(f'Recall: {recall}')\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "\n",
    "\n",
    "true_negative = 128 \n",
    "false_negative = 120 - 110\n",
    "true_positive= 120\n",
    "false_positive = 130 -128\n",
    "accuracy = (true_positive + true_negative) / (true_positive + false_positive + true_negative + false_negative) \n",
    "print(f'Accuracy: {accuracy}')\n",
    "precision = true_positive / (true_positive + false_positive) \n",
    "print(f'Precision: {precision}')   \n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "print(f'Recall: {recall}')\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Accuracy is the same since it measures the overall correctness of the model regardless of class label \n",
    "#Precision is higher when B is the positive class because there are fewer false negatives\n",
    "#Recall is higher when A is positive because there are fewer false negatives\n",
    "#The F1 scores changes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
